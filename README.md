# Coding Assistant with DeepSeek LangChain
![Uploading Screenshot 2025-03-30 at 15.11.26.png‚Ä¶]()

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-red?logo=streamlit)
![LangChain](https://img.shields.io/badge/Powered%20by-LangChain-orange)
![License](https://img.shields.io/badge/License-MIT-green)

## Overview
This project is a **Streamlit-based AI Coding Assistant** powered by **DeepSeek LLM** and **LangChain**. It enables users to interact with an AI model for intelligent responses, leveraging LangChain's capabilities for enhanced conversational experiences.

## Features
- üß† Utilizes **DeepSeek LLM** for natural language processing
- üîó Built with **LangChain** for modular AI workflows
- üé® User-friendly **Streamlit UI** for seamless interaction
- üîÑ Supports contextual conversations and prompt engineering

## Demo
Run the app locally by following the setup instructions below.

## Installation
### Prerequisites
Ensure you have:
- Python 3.9+
- Ollama
- Required dependencies installed

### Setup
Clone the repository:
```bash
git clone https://github.com/Trinita21/deepseek-langchain-assistant.git
cd deepseek-langchain-assistant
```

Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```

Run the Streamlit app:
```bash
streamlit run app.py
```

## Usage
1. Enter your query or code snippet in the chat interface.
2. The AI Assistant, powered by DeepSeek and LangChain, will generate a response.
3. Experiment with different prompts to explore its capabilities.

## Technologies Used
- **DeepSeek LLM** - Core AI model
- **LangChain** - LLM-powered workflow framework
- **Streamlit** - Interactive web UI
- **Python** - Backend processing

---
‚≠ê If you find this project useful, consider starring the repo!

